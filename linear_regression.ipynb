{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X:0\", dtype=float32)\n",
      "Tensor(\"Y:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = W * X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.52549 [ 1.02294493] [ 0.19292164]\n",
      "1 0.0573819 [ 0.92436099] [ 0.14515933]\n",
      "2 0.00385162 [ 0.9368937] [ 0.14638308]\n",
      "3 0.00306178 [ 0.93723971] [ 0.14234899]\n",
      "4 0.00290909 [ 0.93887639] [ 0.13898331]\n",
      "5 0.00277083 [ 0.94033182] [ 0.13563611]\n",
      "6 0.00263921 [ 0.94176769] [ 0.13237616]\n",
      "7 0.00251385 [ 0.94316739] [ 0.12919384]\n",
      "8 0.00239444 [ 0.94453365] [ 0.12608813]\n",
      "9 0.00228069 [ 0.945867] [ 0.12305705]\n",
      "10 0.00217236 [ 0.94716829] [ 0.12009884]\n",
      "11 0.00206918 [ 0.94843835] [ 0.11721174]\n",
      "12 0.00197089 [ 0.94967788] [ 0.11439406]\n",
      "13 0.00187727 [ 0.95088762] [ 0.11164411]\n",
      "14 0.0017881 [ 0.95206821] [ 0.10896025]\n",
      "15 0.00170317 [ 0.95322049] [ 0.10634094]\n",
      "16 0.00162226 [ 0.95434499] [ 0.10378456]\n",
      "17 0.0015452 [ 0.95544249] [ 0.10128965]\n",
      "18 0.0014718 [ 0.95651358] [ 0.09885471]\n",
      "19 0.00140189 [ 0.95755905] [ 0.09647834]\n",
      "20 0.0013353 [ 0.9585793] [ 0.09415907]\n",
      "21 0.00127187 [ 0.959575] [ 0.09189552]\n",
      "22 0.00121145 [ 0.96054679] [ 0.08968642]\n",
      "23 0.00115391 [ 0.96149522] [ 0.0875304]\n",
      "24 0.0010991 [ 0.96242082] [ 0.08542623]\n",
      "25 0.00104689 [ 0.96332425] [ 0.08337265]\n",
      "26 0.000997166 [ 0.96420592] [ 0.08136842]\n",
      "27 0.000949797 [ 0.96506637] [ 0.07941238]\n",
      "28 0.000904682 [ 0.96590614] [ 0.07750335]\n",
      "29 0.000861707 [ 0.96672571] [ 0.07564022]\n",
      "30 0.000820778 [ 0.96752566] [ 0.0738219]\n",
      "31 0.000781787 [ 0.9683063] [ 0.07204726]\n",
      "32 0.000744653 [ 0.96906817] [ 0.07031529]\n",
      "33 0.000709278 [ 0.96981174] [ 0.06862494]\n",
      "34 0.000675588 [ 0.97053748] [ 0.06697526]\n",
      "35 0.000643498 [ 0.97124571] [ 0.0653652]\n",
      "36 0.000612933 [ 0.97193694] [ 0.06379388]\n",
      "37 0.000583818 [ 0.97261155] [ 0.06226032]\n",
      "38 0.000556083 [ 0.97326994] [ 0.06076362]\n",
      "39 0.000529671 [ 0.97391254] [ 0.05930293]\n",
      "40 0.000504511 [ 0.97453964] [ 0.05787731]\n",
      "41 0.000480549 [ 0.97515172] [ 0.05648601]\n",
      "42 0.000457722 [ 0.97574908] [ 0.05512813]\n",
      "43 0.00043598 [ 0.97633201] [ 0.05380287]\n",
      "44 0.000415269 [ 0.97690094] [ 0.05250948]\n",
      "45 0.000395544 [ 0.97745627] [ 0.05124722]\n",
      "46 0.000376757 [ 0.97799826] [ 0.05001527]\n",
      "47 0.000358861 [ 0.97852713] [ 0.04881292]\n",
      "48 0.000341814 [ 0.9790433] [ 0.04763948]\n",
      "49 0.000325576 [ 0.97954708] [ 0.04649427]\n",
      "50 0.000310112 [ 0.98003876] [ 0.04537657]\n",
      "51 0.00029538 [ 0.98051864] [ 0.04428575]\n",
      "52 0.000281349 [ 0.98098695] [ 0.04322115]\n",
      "53 0.000267986 [ 0.981444] [ 0.04218213]\n",
      "54 0.000255254 [ 0.98189002] [ 0.04116809]\n",
      "55 0.000243131 [ 0.98232543] [ 0.04017847]\n",
      "56 0.000231583 [ 0.9827503] [ 0.0392126]\n",
      "57 0.000220583 [ 0.98316497] [ 0.03826996]\n",
      "58 0.000210104 [ 0.98356968] [ 0.03734999]\n",
      "59 0.000200125 [ 0.98396462] [ 0.03645211]\n",
      "60 0.00019062 [ 0.98435014] [ 0.03557584]\n",
      "61 0.000181563 [ 0.98472637] [ 0.03472063]\n",
      "62 0.000172939 [ 0.98509353] [ 0.03388597]\n",
      "63 0.000164726 [ 0.98545182] [ 0.03307135]\n",
      "64 0.0001569 [ 0.98580158] [ 0.03227635]\n",
      "65 0.000149449 [ 0.98614293] [ 0.03150045]\n",
      "66 0.000142348 [ 0.986476] [ 0.0307432]\n",
      "67 0.000135587 [ 0.98680115] [ 0.03000416]\n",
      "68 0.000129146 [ 0.98711836] [ 0.02928285]\n",
      "69 0.000123011 [ 0.98742807] [ 0.02857894]\n",
      "70 0.000117169 [ 0.98773032] [ 0.02789193]\n",
      "71 0.000111603 [ 0.98802525] [ 0.02722141]\n",
      "72 0.000106301 [ 0.98831314] [ 0.02656703]\n",
      "73 0.000101253 [ 0.98859406] [ 0.02592837]\n",
      "74 9.64433e-05 [ 0.9888683] [ 0.02530508]\n",
      "75 9.18619e-05 [ 0.98913586] [ 0.02469674]\n",
      "76 8.74969e-05 [ 0.98939699] [ 0.02410303]\n",
      "77 8.33423e-05 [ 0.98965198] [ 0.02352364]\n",
      "78 7.93831e-05 [ 0.98990065] [ 0.02295812]\n",
      "79 7.56123e-05 [ 0.99014348] [ 0.02240624]\n",
      "80 7.20208e-05 [ 0.99038041] [ 0.0218676]\n",
      "81 6.85996e-05 [ 0.99061167] [ 0.02134191]\n",
      "82 6.53408e-05 [ 0.99083734] [ 0.02082887]\n",
      "83 6.22369e-05 [ 0.99105757] [ 0.02032815]\n",
      "84 5.92814e-05 [ 0.99127263] [ 0.0198395]\n",
      "85 5.64648e-05 [ 0.99148238] [ 0.01936257]\n",
      "86 5.37828e-05 [ 0.99168712] [ 0.01889711]\n",
      "87 5.12285e-05 [ 0.99188697] [ 0.01844283]\n",
      "88 4.87955e-05 [ 0.992082] [ 0.01799948]\n",
      "89 4.64781e-05 [ 0.99227238] [ 0.0175668]\n",
      "90 4.42697e-05 [ 0.99245816] [ 0.0171445]\n",
      "91 4.21666e-05 [ 0.99263942] [ 0.01673233]\n",
      "92 4.01643e-05 [ 0.99281645] [ 0.01633012]\n",
      "93 3.8256e-05 [ 0.99298906] [ 0.01593753]\n",
      "94 3.64387e-05 [ 0.99315757] [ 0.01555439]\n",
      "95 3.47076e-05 [ 0.99332207] [ 0.0151805]\n",
      "96 3.30592e-05 [ 0.99348259] [ 0.01481557]\n",
      "97 3.14888e-05 [ 0.99363929] [ 0.01445942]\n",
      "98 2.99932e-05 [ 0.99379218] [ 0.01411181]\n",
      "99 2.85678e-05 [ 0.99394143] [ 0.01377258]\n",
      "X: 5, Y: [ 4.9834795]\n",
      "X: 2.5, Y: [ 2.49862599]\n"
     ]
    }
   ],
   "source": [
    "x_data = [1,2,3]\n",
    "y_data = [1,2,3]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100):\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data,\n",
    "                                                           Y:y_data})\n",
    "        print(step, cost_val, sess.run(W), sess.run(b))\n",
    "        \n",
    "    print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X:5}))\n",
    "    print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X:2.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
